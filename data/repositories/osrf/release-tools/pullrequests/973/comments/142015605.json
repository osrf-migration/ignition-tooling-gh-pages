{"links": {"self": {"href": "data/repositories/osrf/release-tools/pullrequests/973/comments/142015605.json"}, "html": {"href": "#!/osrf/release-tools/pull-requests/973/_/diff#comment-142015605"}}, "parent": {"id": 142012225, "links": {"self": {"href": "data/repositories/osrf/release-tools/pullrequests/973/comments/142012225.json"}, "html": {"href": "#!/osrf/release-tools/pull-requests/973/_/diff#comment-142012225"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 973, "links": {"self": {"href": "data/repositories/osrf/release-tools/pullrequests/973.json"}, "html": {"href": "#!/osrf/release-tools/pull-requests/973"}}, "title": "Install libglvnd if using nvidia-docker2"}, "content": {"raw": "> I might be wrong but my impression about this bug is that something is somehow killing the X server in drogon \\(probably a non controlled number of jobs compilation that ate all the RAM\\) and when it\u2019s back it is not using graphic acceleration. If drogon is rebooted the current setup seems to work fine until problems arise.\n\nHmm maybe the X server was killed and restarted. Drogon has been up for 22 days, b the Xorg process on `drogon` has been up for only 7 days.\n\n```\nubuntu@ip-10-191-49-253:~$ uptime\n 23:17:38 up 22 days,  6:28,  1 user,  load average: 0.00, 0.00, 0.17\n```\n\n```\n$ ps -ef | grep Xorg\nroot      2482  2476  0 Mar18 tty7     00:00:21 /usr/lib/xorg/Xorg -core :0 -seat seat0 -auth /var/run/lightdm/root/:0 -nolisten tcp vt7 -novtswitch\n```\n\n```\n$ ps -o etime -p 2482\n    ELAPSED\n 7-00:42:30\n```\n\nCoincidentally, a lot of jobs failed with a java traceback followed by no disk space `7 days 0 hr` ago \\(the 7 day 3 hr ago job failures look unrelated\\).\n\n![](data/bitbucket.org/repo/ngjznb/images/3559626744-Screenshot_from_2020-03-25_16-25-53.png)\n\u200c\n\nHowever; it doesn\u2019t seem to be related to the `swrast` failure. Before that incident the gazebo10 jobs are failing with the same `swrast` error\n\nLike this one 7 days 11 hours ago\n\n[https://build.osrfoundation.org/job/gazebo-install-gazebo10\\_pkg-xenial-amd64/433/console](https://build.osrfoundation.org/job/gazebo-install-gazebo10_pkg-xenial-amd64/433/console)\n\nOr this one 14 days ago\n\n[https://build.osrfoundation.org/job/gazebo-install-gazebo10\\_pkg-xenial-amd64/426](https://build.osrfoundation.org/job/gazebo-install-gazebo10_pkg-xenial-amd64/426)\n\n\u200c\n\nInterestingly, none of the gazebo11 jobs I found failed with the `swrast` error. What makes that job special?\n\n[https://build.osrfoundation.org/job/gazebo-install-gazebo11\\_pkg-bionic-amd64/53/console](https://build.osrfoundation.org/job/gazebo-install-gazebo11_pkg-bionic-amd64/53/console)\n\n\u200c\n\n> What does glxinfo display when using this setup inside the container in drogon?\n\nI haven\u2019t tried to run glxinfo inside the container of a job \\(I\u2019ll work on that\\), but here\u2019s what it looks like outside the container.\n\n[https://gist.github.com/sloretz/d63c8311e329048c1c9ac1972682480f](https://gist.github.com/sloretz/d63c8311e329048c1c9ac1972682480f)", "markup": "markdown", "html": "<blockquote>\n<p>I might be wrong but my impression about this bug is that something is somehow killing the X server in drogon (probably a non controlled number of jobs compilation that ate all the RAM) and when it\u2019s back it is not using graphic acceleration. If drogon is rebooted the current setup seems to work fine until problems arise.</p>\n</blockquote>\n<p>Hmm maybe the X server was killed and restarted. Drogon has been up for 22 days, b the Xorg process on <code>drogon</code> has been up for only 7 days.</p>\n<div class=\"codehilite\"><pre><span></span>ubuntu@ip-10-191-49-253:~$ uptime\n 23:17:38 up 22 days,  6:28,  1 user,  load average: 0.00, 0.00, 0.17\n</pre></div>\n\n\n<div class=\"codehilite\"><pre><span></span>$ ps -ef <span class=\"p\">|</span> grep Xorg\nroot      <span class=\"m\">2482</span>  <span class=\"m\">2476</span>  <span class=\"m\">0</span> Mar18 tty7     <span class=\"m\">00</span>:00:21 /usr/lib/xorg/Xorg -core :0 -seat seat0 -auth /var/run/lightdm/root/:0 -nolisten tcp vt7 -novtswitch\n</pre></div>\n\n\n<div class=\"codehilite\"><pre><span></span>$ ps -o etime -p <span class=\"m\">2482</span>\n    ELAPSED\n <span class=\"m\">7</span>-00:42:30\n</pre></div>\n\n\n<p>Coincidentally, a lot of jobs failed with a java traceback followed by no disk space <code>7 days 0 hr</code> ago (the 7 day 3 hr ago job failures look unrelated).</p>\n<p><img alt=\"\" src=\"data/bitbucket.org/repo/ngjznb/images/3559626744-Screenshot_from_2020-03-25_16-25-53.png\" />\n\u200c</p>\n<p>However; it doesn\u2019t seem to be related to the <code>swrast</code> failure. Before that incident the gazebo10 jobs are failing with the same <code>swrast</code> error</p>\n<p>Like this one 7 days 11 hours ago</p>\n<p><a data-is-external-link=\"true\" href=\"https://build.osrfoundation.org/job/gazebo-install-gazebo10_pkg-xenial-amd64/433/console\" rel=\"nofollow\">https://build.osrfoundation.org/job/gazebo-install-gazebo10_pkg-xenial-amd64/433/console</a></p>\n<p>Or this one 14 days ago</p>\n<p><a data-is-external-link=\"true\" href=\"https://build.osrfoundation.org/job/gazebo-install-gazebo10_pkg-xenial-amd64/426\" rel=\"nofollow\">https://build.osrfoundation.org/job/gazebo-install-gazebo10_pkg-xenial-amd64/426</a></p>\n<p>\u200c</p>\n<p>Interestingly, none of the gazebo11 jobs I found failed with the <code>swrast</code> error. What makes that job special?</p>\n<p><a data-is-external-link=\"true\" href=\"https://build.osrfoundation.org/job/gazebo-install-gazebo11_pkg-bionic-amd64/53/console\" rel=\"nofollow\">https://build.osrfoundation.org/job/gazebo-install-gazebo11_pkg-bionic-amd64/53/console</a></p>\n<p>\u200c</p>\n<blockquote>\n<p>What does glxinfo display when using this setup inside the container in drogon?</p>\n</blockquote>\n<p>I haven\u2019t tried to run glxinfo inside the container of a job (I\u2019ll work on that), but here\u2019s what it looks like outside the container.</p>\n<p><a data-is-external-link=\"true\" href=\"https://gist.github.com/sloretz/d63c8311e329048c1c9ac1972682480f\" rel=\"nofollow\">https://gist.github.com/sloretz/d63c8311e329048c1c9ac1972682480f</a></p>", "type": "rendered"}, "created_on": "2020-03-25T23:35:52.922849+00:00", "user": {"display_name": "Shane Loretz", "uuid": "{656e3311-aad9-45a1-aaf7-b0ee0e84b287}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B656e3311-aad9-45a1-aaf7-b0ee0e84b287%7D"}, "html": {"href": "https://bitbucket.org/%7B656e3311-aad9-45a1-aaf7-b0ee0e84b287%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:684383ab-ac95-4859-a350-4a6f41a94a22/c7a1ebf5-cade-4115-9f26-9d3facb776db/128"}}, "nickname": "Shane Loretz", "type": "user", "account_id": "557058:684383ab-ac95-4859-a350-4a6f41a94a22"}, "updated_on": "2020-03-25T23:48:50.292077+00:00", "type": "pullrequest_comment", "id": 142015605}